{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation: ECO-Lite\n",
    "\n",
    "This file implements the ECO-Lite model and classifies the video data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preperation\n",
    "\n",
    "-Download and place \"ECO_Lite_rgb_model_Kinetics.pth.tar\" in the folder \"weights\".\n",
    "\n",
    "https://github.com/mzolfaghari/ECO-pytorch „ÅÆ\n",
    "\n",
    "https://drive.google.com/open?id=1XNIq7byciKgrn011jLBggd2g79jKX4uD\n",
    "\n",
    "\n",
    "-The contents of implementation from 9.2 to 9.4 are prepared in the folder \"utils\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = \"./weights/\"\n",
    "if not os.path.exists(weights_dir):\n",
    "    os.mkdir(weights_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader for Kinematics \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 16, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from utils.kinetics400_eco_dataloader import make_datapath_list, VideoTransform, get_label_id_dictionary, VideoDataset\n",
    "\n",
    "root_path = './data/kinetics_videos/'\n",
    "video_list = make_datapath_list(root_path)\n",
    "\n",
    "resize, crop_size = 224, 224\n",
    "mean, std = [104, 117, 123], [1, 1, 1]\n",
    "video_transform = VideoTransform(resize, crop_size, mean, std)\n",
    "\n",
    "label_dicitionary_path = 'kinetics_400_label_dicitionary.csv'\n",
    "label_id_dict, id_label_dict = get_label_id_dictionary(label_dicitionary_path)\n",
    "\n",
    "\n",
    "val_dataset = VideoDataset(video_list, label_id_dict, num_segments=16,\n",
    "                           phase=\"val\", transform=video_transform, img_tmpl='image_{:05d}.jpg')\n",
    "\n",
    "batch_size = 8\n",
    "val_dataloader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "batch_iterator = iter(val_dataloader)  \n",
    "imgs_transformeds, labels, label_ids, dir_path = next(\n",
    "    batch_iterator)  \n",
    "print(imgs_transformeds.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECO-Lite Implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.eco import ECO_2D, ECO_3D\n",
    "\n",
    "\n",
    "class ECO_Lite(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ECO_Lite, self).__init__()\n",
    "\n",
    "       \n",
    "        self.eco_2d = ECO_2D()\n",
    "\n",
    "        \n",
    "        self.eco_3d = ECO_3D()\n",
    "\n",
    "        \n",
    "        self.fc_final = nn.Linear(in_features=512, out_features=400, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        \n",
    "        bs, ns, c, h, w = x.shape\n",
    "\n",
    "        \n",
    "        out = x.view(-1, c, h, w)\n",
    "\n",
    "        out = self.eco_2d(out)\n",
    "\n",
    "        out = out.view(-1, ns, 96, 28, 28)\n",
    "\n",
    "        out = self.eco_3d(out)\n",
    "\n",
    "        out = self.fc_final(out)\n",
    "        \n",
    "        \n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pre-Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ECO_Lite(\n",
       "  (eco_2d): ECO_2D(\n",
       "    (basic_conv): BasicConv(\n",
       "      (conv1_7x7_s2): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
       "      (conv1_7x7_s2_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv1_relu_7x7): ReLU(inplace)\n",
       "      (pool1_3x3_s2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "      (conv2_3x3_reduce): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv2_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2_relu_3x3_reduce): ReLU(inplace)\n",
       "      (conv2_3x3): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2_3x3_bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2_relu_3x3): ReLU(inplace)\n",
       "      (pool2_3x3_s2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "    )\n",
       "    (inception_a): InceptionA(\n",
       "      (inception_3a_1x1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3a_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_1x1): ReLU(inplace)\n",
       "      (inception_3a_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3a_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_3x3_reduce): ReLU(inplace)\n",
       "      (inception_3a_3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3a_3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_3x3): ReLU(inplace)\n",
       "      (inception_3a_double_3x3_reduce): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3a_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_double_3x3_reduce): ReLU(inplace)\n",
       "      (inception_3a_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3a_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_double_3x3_1): ReLU(inplace)\n",
       "      (inception_3a_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3a_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_double_3x3_2): ReLU(inplace)\n",
       "      (inception_3a_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "      (inception_3a_pool_proj): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3a_pool_proj_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3a_relu_pool_proj): ReLU(inplace)\n",
       "    )\n",
       "    (inception_b): InceptionB(\n",
       "      (inception_3b_1x1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3b_1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_1x1): ReLU(inplace)\n",
       "      (inception_3b_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3b_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_3x3_reduce): ReLU(inplace)\n",
       "      (inception_3b_3x3): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3b_3x3_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_3x3): ReLU(inplace)\n",
       "      (inception_3b_double_3x3_reduce): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3b_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_double_3x3_reduce): ReLU(inplace)\n",
       "      (inception_3b_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3b_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_double_3x3_1): ReLU(inplace)\n",
       "      (inception_3b_double_3x3_2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3b_double_3x3_2_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_double_3x3_2): ReLU(inplace)\n",
       "      (inception_3b_pool): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
       "      (inception_3b_pool_proj): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3b_pool_proj_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3b_relu_pool_proj): ReLU(inplace)\n",
       "    )\n",
       "    (inception_c): InceptionC(\n",
       "      (inception_3c_double_3x3_reduce): Conv2d(320, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (inception_3c_double_3x3_reduce_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3c_relu_double_3x3_reduce): ReLU(inplace)\n",
       "      (inception_3c_double_3x3_1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (inception_3c_double_3x3_1_bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (inception_3c_relu_double_3x3_1): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (eco_3d): ECO_3D(\n",
       "    (res_3d_3): Resnet_3D_3(\n",
       "      (res3a_2): Conv3d(96, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res3a_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res3a_relu): ReLU(inplace)\n",
       "      (res3b_1): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res3b_1_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res3b_1_relu): ReLU(inplace)\n",
       "      (res3b_2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res3b_bn): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res3b_relu): ReLU(inplace)\n",
       "    )\n",
       "    (res_3d_4): Resnet_3D_4(\n",
       "      (res4a_1): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (res4a_1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res4a_1_relu): ReLU(inplace)\n",
       "      (res4a_2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res4a_down): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (res4a_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res4a_relu): ReLU(inplace)\n",
       "      (res4b_1): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res4b_1_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res4b_1_relu): ReLU(inplace)\n",
       "      (res4b_2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res4b_bn): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res4b_relu): ReLU(inplace)\n",
       "    )\n",
       "    (res_3d_5): Resnet_3D_5(\n",
       "      (res5a_1): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (res5a_1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res5a_1_relu): ReLU(inplace)\n",
       "      (res5a_2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res5a_down): Conv3d(256, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "      (res5a_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res5a_relu): ReLU(inplace)\n",
       "      (res5b_1): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res5b_1_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res5b_1_relu): ReLU(inplace)\n",
       "      (res5b_2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "      (res5b_bn): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (res5b_relu): ReLU(inplace)\n",
       "    )\n",
       "    (global_pool): AvgPool3d(kernel_size=(4, 7, 7), stride=1, padding=0)\n",
       "  )\n",
       "  (fc_final): Linear(in_features=512, out_features=400, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ECO_Lite()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_ECO(model_dict, pretrained_model_dict):\n",
    "\n",
    "    param_names = [] \n",
    "    for name, param in model_dict.items():\n",
    "        param_names.append(name)\n",
    "\n",
    "    new_state_dict = model_dict.copy()\n",
    "\n",
    "    print(\"Load learned parameters\")\n",
    "    for index, (key_name, value) in enumerate(pretrained_model_dict.items()):\n",
    "        name = param_names[index]  \n",
    "        new_state_dict[name] = value  \n",
    "\n",
    "        print(str(key_name)+\"‚Üí\"+str(name))\n",
    "\n",
    "    return new_state_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load learned parameters\n",
      "module.base_model.conv1_7x7_s2.weight‚Üíeco_2d.basic_conv.conv1_7x7_s2.weight\n",
      "module.base_model.conv1_7x7_s2.bias‚Üíeco_2d.basic_conv.conv1_7x7_s2.bias\n",
      "module.base_model.conv1_7x7_s2_bn.weight‚Üíeco_2d.basic_conv.conv1_7x7_s2_bn.weight\n",
      "module.base_model.conv1_7x7_s2_bn.bias‚Üíeco_2d.basic_conv.conv1_7x7_s2_bn.bias\n",
      "module.base_model.conv1_7x7_s2_bn.running_mean‚Üíeco_2d.basic_conv.conv1_7x7_s2_bn.running_mean\n",
      "module.base_model.conv1_7x7_s2_bn.running_var‚Üíeco_2d.basic_conv.conv1_7x7_s2_bn.running_var\n",
      "module.base_model.conv1_7x7_s2_bn.num_batches_tracked‚Üíeco_2d.basic_conv.conv1_7x7_s2_bn.num_batches_tracked\n",
      "module.base_model.conv2_3x3_reduce.weight‚Üíeco_2d.basic_conv.conv2_3x3_reduce.weight\n",
      "module.base_model.conv2_3x3_reduce.bias‚Üíeco_2d.basic_conv.conv2_3x3_reduce.bias\n",
      "module.base_model.conv2_3x3_reduce_bn.weight‚Üíeco_2d.basic_conv.conv2_3x3_reduce_bn.weight\n",
      "module.base_model.conv2_3x3_reduce_bn.bias‚Üíeco_2d.basic_conv.conv2_3x3_reduce_bn.bias\n",
      "module.base_model.conv2_3x3_reduce_bn.running_mean‚Üíeco_2d.basic_conv.conv2_3x3_reduce_bn.running_mean\n",
      "module.base_model.conv2_3x3_reduce_bn.running_var‚Üíeco_2d.basic_conv.conv2_3x3_reduce_bn.running_var\n",
      "module.base_model.conv2_3x3_reduce_bn.num_batches_tracked‚Üíeco_2d.basic_conv.conv2_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.conv2_3x3.weight‚Üíeco_2d.basic_conv.conv2_3x3.weight\n",
      "module.base_model.conv2_3x3.bias‚Üíeco_2d.basic_conv.conv2_3x3.bias\n",
      "module.base_model.conv2_3x3_bn.weight‚Üíeco_2d.basic_conv.conv2_3x3_bn.weight\n",
      "module.base_model.conv2_3x3_bn.bias‚Üíeco_2d.basic_conv.conv2_3x3_bn.bias\n",
      "module.base_model.conv2_3x3_bn.running_mean‚Üíeco_2d.basic_conv.conv2_3x3_bn.running_mean\n",
      "module.base_model.conv2_3x3_bn.running_var‚Üíeco_2d.basic_conv.conv2_3x3_bn.running_var\n",
      "module.base_model.conv2_3x3_bn.num_batches_tracked‚Üíeco_2d.basic_conv.conv2_3x3_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_1x1.weight‚Üíeco_2d.inception_a.inception_3a_1x1.weight\n",
      "module.base_model.inception_3a_1x1.bias‚Üíeco_2d.inception_a.inception_3a_1x1.bias\n",
      "module.base_model.inception_3a_1x1_bn.weight‚Üíeco_2d.inception_a.inception_3a_1x1_bn.weight\n",
      "module.base_model.inception_3a_1x1_bn.bias‚Üíeco_2d.inception_a.inception_3a_1x1_bn.bias\n",
      "module.base_model.inception_3a_1x1_bn.running_mean‚Üíeco_2d.inception_a.inception_3a_1x1_bn.running_mean\n",
      "module.base_model.inception_3a_1x1_bn.running_var‚Üíeco_2d.inception_a.inception_3a_1x1_bn.running_var\n",
      "module.base_model.inception_3a_1x1_bn.num_batches_tracked‚Üíeco_2d.inception_a.inception_3a_1x1_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_3x3_reduce.weight‚Üíeco_2d.inception_a.inception_3a_3x3_reduce.weight\n",
      "module.base_model.inception_3a_3x3_reduce.bias‚Üíeco_2d.inception_a.inception_3a_3x3_reduce.bias\n",
      "module.base_model.inception_3a_3x3_reduce_bn.weight‚Üíeco_2d.inception_a.inception_3a_3x3_reduce_bn.weight\n",
      "module.base_model.inception_3a_3x3_reduce_bn.bias‚Üíeco_2d.inception_a.inception_3a_3x3_reduce_bn.bias\n",
      "module.base_model.inception_3a_3x3_reduce_bn.running_mean‚Üíeco_2d.inception_a.inception_3a_3x3_reduce_bn.running_mean\n",
      "module.base_model.inception_3a_3x3_reduce_bn.running_var‚Üíeco_2d.inception_a.inception_3a_3x3_reduce_bn.running_var\n",
      "module.base_model.inception_3a_3x3_reduce_bn.num_batches_tracked‚Üíeco_2d.inception_a.inception_3a_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_3x3.weight‚Üíeco_2d.inception_a.inception_3a_3x3.weight\n",
      "module.base_model.inception_3a_3x3.bias‚Üíeco_2d.inception_a.inception_3a_3x3.bias\n",
      "module.base_model.inception_3a_3x3_bn.weight‚Üíeco_2d.inception_a.inception_3a_3x3_bn.weight\n",
      "module.base_model.inception_3a_3x3_bn.bias‚Üíeco_2d.inception_a.inception_3a_3x3_bn.bias\n",
      "module.base_model.inception_3a_3x3_bn.running_mean‚Üíeco_2d.inception_a.inception_3a_3x3_bn.running_mean\n",
      "module.base_model.inception_3a_3x3_bn.running_var‚Üíeco_2d.inception_a.inception_3a_3x3_bn.running_var\n",
      "module.base_model.inception_3a_3x3_bn.num_batches_tracked‚Üíeco_2d.inception_a.inception_3a_3x3_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_double_3x3_reduce.weight‚Üíeco_2d.inception_a.inception_3a_double_3x3_reduce.weight\n",
      "module.base_model.inception_3a_double_3x3_reduce.bias‚Üíeco_2d.inception_a.inception_3a_double_3x3_reduce.bias\n",
      "module.base_model.inception_3a_double_3x3_reduce_bn.weight‚Üíeco_2d.inception_a.inception_3a_double_3x3_reduce_bn.weight\n",
      "module.base_model.inception_3a_double_3x3_reduce_bn.bias‚Üíeco_2d.inception_a.inception_3a_double_3x3_reduce_bn.bias\n",
      "module.base_model.inception_3a_double_3x3_reduce_bn.running_mean‚Üíeco_2d.inception_a.inception_3a_double_3x3_reduce_bn.running_mean\n",
      "module.base_model.inception_3a_double_3x3_reduce_bn.running_var‚Üíeco_2d.inception_a.inception_3a_double_3x3_reduce_bn.running_var\n",
      "module.base_model.inception_3a_double_3x3_reduce_bn.num_batches_tracked‚Üíeco_2d.inception_a.inception_3a_double_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_double_3x3_1.weight‚Üíeco_2d.inception_a.inception_3a_double_3x3_1.weight\n",
      "module.base_model.inception_3a_double_3x3_1.bias‚Üíeco_2d.inception_a.inception_3a_double_3x3_1.bias\n",
      "module.base_model.inception_3a_double_3x3_1_bn.weight‚Üíeco_2d.inception_a.inception_3a_double_3x3_1_bn.weight\n",
      "module.base_model.inception_3a_double_3x3_1_bn.bias‚Üíeco_2d.inception_a.inception_3a_double_3x3_1_bn.bias\n",
      "module.base_model.inception_3a_double_3x3_1_bn.running_mean‚Üíeco_2d.inception_a.inception_3a_double_3x3_1_bn.running_mean\n",
      "module.base_model.inception_3a_double_3x3_1_bn.running_var‚Üíeco_2d.inception_a.inception_3a_double_3x3_1_bn.running_var\n",
      "module.base_model.inception_3a_double_3x3_1_bn.num_batches_tracked‚Üíeco_2d.inception_a.inception_3a_double_3x3_1_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_double_3x3_2.weight‚Üíeco_2d.inception_a.inception_3a_double_3x3_2.weight\n",
      "module.base_model.inception_3a_double_3x3_2.bias‚Üíeco_2d.inception_a.inception_3a_double_3x3_2.bias\n",
      "module.base_model.inception_3a_double_3x3_2_bn.weight‚Üíeco_2d.inception_a.inception_3a_double_3x3_2_bn.weight\n",
      "module.base_model.inception_3a_double_3x3_2_bn.bias‚Üíeco_2d.inception_a.inception_3a_double_3x3_2_bn.bias\n",
      "module.base_model.inception_3a_double_3x3_2_bn.running_mean‚Üíeco_2d.inception_a.inception_3a_double_3x3_2_bn.running_mean\n",
      "module.base_model.inception_3a_double_3x3_2_bn.running_var‚Üíeco_2d.inception_a.inception_3a_double_3x3_2_bn.running_var\n",
      "module.base_model.inception_3a_double_3x3_2_bn.num_batches_tracked‚Üíeco_2d.inception_a.inception_3a_double_3x3_2_bn.num_batches_tracked\n",
      "module.base_model.inception_3a_pool_proj.weight‚Üíeco_2d.inception_a.inception_3a_pool_proj.weight\n",
      "module.base_model.inception_3a_pool_proj.bias‚Üíeco_2d.inception_a.inception_3a_pool_proj.bias\n",
      "module.base_model.inception_3a_pool_proj_bn.weight‚Üíeco_2d.inception_a.inception_3a_pool_proj_bn.weight\n",
      "module.base_model.inception_3a_pool_proj_bn.bias‚Üíeco_2d.inception_a.inception_3a_pool_proj_bn.bias\n",
      "module.base_model.inception_3a_pool_proj_bn.running_mean‚Üíeco_2d.inception_a.inception_3a_pool_proj_bn.running_mean\n",
      "module.base_model.inception_3a_pool_proj_bn.running_var‚Üíeco_2d.inception_a.inception_3a_pool_proj_bn.running_var\n",
      "module.base_model.inception_3a_pool_proj_bn.num_batches_tracked‚Üíeco_2d.inception_a.inception_3a_pool_proj_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_1x1.weight‚Üíeco_2d.inception_b.inception_3b_1x1.weight\n",
      "module.base_model.inception_3b_1x1.bias‚Üíeco_2d.inception_b.inception_3b_1x1.bias\n",
      "module.base_model.inception_3b_1x1_bn.weight‚Üíeco_2d.inception_b.inception_3b_1x1_bn.weight\n",
      "module.base_model.inception_3b_1x1_bn.bias‚Üíeco_2d.inception_b.inception_3b_1x1_bn.bias\n",
      "module.base_model.inception_3b_1x1_bn.running_mean‚Üíeco_2d.inception_b.inception_3b_1x1_bn.running_mean\n",
      "module.base_model.inception_3b_1x1_bn.running_var‚Üíeco_2d.inception_b.inception_3b_1x1_bn.running_var\n",
      "module.base_model.inception_3b_1x1_bn.num_batches_tracked‚Üíeco_2d.inception_b.inception_3b_1x1_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_3x3_reduce.weight‚Üíeco_2d.inception_b.inception_3b_3x3_reduce.weight\n",
      "module.base_model.inception_3b_3x3_reduce.bias‚Üíeco_2d.inception_b.inception_3b_3x3_reduce.bias\n",
      "module.base_model.inception_3b_3x3_reduce_bn.weight‚Üíeco_2d.inception_b.inception_3b_3x3_reduce_bn.weight\n",
      "module.base_model.inception_3b_3x3_reduce_bn.bias‚Üíeco_2d.inception_b.inception_3b_3x3_reduce_bn.bias\n",
      "module.base_model.inception_3b_3x3_reduce_bn.running_mean‚Üíeco_2d.inception_b.inception_3b_3x3_reduce_bn.running_mean\n",
      "module.base_model.inception_3b_3x3_reduce_bn.running_var‚Üíeco_2d.inception_b.inception_3b_3x3_reduce_bn.running_var\n",
      "module.base_model.inception_3b_3x3_reduce_bn.num_batches_tracked‚Üíeco_2d.inception_b.inception_3b_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_3x3.weight‚Üíeco_2d.inception_b.inception_3b_3x3.weight\n",
      "module.base_model.inception_3b_3x3.bias‚Üíeco_2d.inception_b.inception_3b_3x3.bias\n",
      "module.base_model.inception_3b_3x3_bn.weight‚Üíeco_2d.inception_b.inception_3b_3x3_bn.weight\n",
      "module.base_model.inception_3b_3x3_bn.bias‚Üíeco_2d.inception_b.inception_3b_3x3_bn.bias\n",
      "module.base_model.inception_3b_3x3_bn.running_mean‚Üíeco_2d.inception_b.inception_3b_3x3_bn.running_mean\n",
      "module.base_model.inception_3b_3x3_bn.running_var‚Üíeco_2d.inception_b.inception_3b_3x3_bn.running_var\n",
      "module.base_model.inception_3b_3x3_bn.num_batches_tracked‚Üíeco_2d.inception_b.inception_3b_3x3_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_double_3x3_reduce.weight‚Üíeco_2d.inception_b.inception_3b_double_3x3_reduce.weight\n",
      "module.base_model.inception_3b_double_3x3_reduce.bias‚Üíeco_2d.inception_b.inception_3b_double_3x3_reduce.bias\n",
      "module.base_model.inception_3b_double_3x3_reduce_bn.weight‚Üíeco_2d.inception_b.inception_3b_double_3x3_reduce_bn.weight\n",
      "module.base_model.inception_3b_double_3x3_reduce_bn.bias‚Üíeco_2d.inception_b.inception_3b_double_3x3_reduce_bn.bias\n",
      "module.base_model.inception_3b_double_3x3_reduce_bn.running_mean‚Üíeco_2d.inception_b.inception_3b_double_3x3_reduce_bn.running_mean\n",
      "module.base_model.inception_3b_double_3x3_reduce_bn.running_var‚Üíeco_2d.inception_b.inception_3b_double_3x3_reduce_bn.running_var\n",
      "module.base_model.inception_3b_double_3x3_reduce_bn.num_batches_tracked‚Üíeco_2d.inception_b.inception_3b_double_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_double_3x3_1.weight‚Üíeco_2d.inception_b.inception_3b_double_3x3_1.weight\n",
      "module.base_model.inception_3b_double_3x3_1.bias‚Üíeco_2d.inception_b.inception_3b_double_3x3_1.bias\n",
      "module.base_model.inception_3b_double_3x3_1_bn.weight‚Üíeco_2d.inception_b.inception_3b_double_3x3_1_bn.weight\n",
      "module.base_model.inception_3b_double_3x3_1_bn.bias‚Üíeco_2d.inception_b.inception_3b_double_3x3_1_bn.bias\n",
      "module.base_model.inception_3b_double_3x3_1_bn.running_mean‚Üíeco_2d.inception_b.inception_3b_double_3x3_1_bn.running_mean\n",
      "module.base_model.inception_3b_double_3x3_1_bn.running_var‚Üíeco_2d.inception_b.inception_3b_double_3x3_1_bn.running_var\n",
      "module.base_model.inception_3b_double_3x3_1_bn.num_batches_tracked‚Üíeco_2d.inception_b.inception_3b_double_3x3_1_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_double_3x3_2.weight‚Üíeco_2d.inception_b.inception_3b_double_3x3_2.weight\n",
      "module.base_model.inception_3b_double_3x3_2.bias‚Üíeco_2d.inception_b.inception_3b_double_3x3_2.bias\n",
      "module.base_model.inception_3b_double_3x3_2_bn.weight‚Üíeco_2d.inception_b.inception_3b_double_3x3_2_bn.weight\n",
      "module.base_model.inception_3b_double_3x3_2_bn.bias‚Üíeco_2d.inception_b.inception_3b_double_3x3_2_bn.bias\n",
      "module.base_model.inception_3b_double_3x3_2_bn.running_mean‚Üíeco_2d.inception_b.inception_3b_double_3x3_2_bn.running_mean\n",
      "module.base_model.inception_3b_double_3x3_2_bn.running_var‚Üíeco_2d.inception_b.inception_3b_double_3x3_2_bn.running_var\n",
      "module.base_model.inception_3b_double_3x3_2_bn.num_batches_tracked‚Üíeco_2d.inception_b.inception_3b_double_3x3_2_bn.num_batches_tracked\n",
      "module.base_model.inception_3b_pool_proj.weight‚Üíeco_2d.inception_b.inception_3b_pool_proj.weight\n",
      "module.base_model.inception_3b_pool_proj.bias‚Üíeco_2d.inception_b.inception_3b_pool_proj.bias\n",
      "module.base_model.inception_3b_pool_proj_bn.weight‚Üíeco_2d.inception_b.inception_3b_pool_proj_bn.weight\n",
      "module.base_model.inception_3b_pool_proj_bn.bias‚Üíeco_2d.inception_b.inception_3b_pool_proj_bn.bias\n",
      "module.base_model.inception_3b_pool_proj_bn.running_mean‚Üíeco_2d.inception_b.inception_3b_pool_proj_bn.running_mean\n",
      "module.base_model.inception_3b_pool_proj_bn.running_var‚Üíeco_2d.inception_b.inception_3b_pool_proj_bn.running_var\n",
      "module.base_model.inception_3b_pool_proj_bn.num_batches_tracked‚Üíeco_2d.inception_b.inception_3b_pool_proj_bn.num_batches_tracked\n",
      "module.base_model.inception_3c_double_3x3_reduce.weight‚Üíeco_2d.inception_c.inception_3c_double_3x3_reduce.weight\n",
      "module.base_model.inception_3c_double_3x3_reduce.bias‚Üíeco_2d.inception_c.inception_3c_double_3x3_reduce.bias\n",
      "module.base_model.inception_3c_double_3x3_reduce_bn.weight‚Üíeco_2d.inception_c.inception_3c_double_3x3_reduce_bn.weight\n",
      "module.base_model.inception_3c_double_3x3_reduce_bn.bias‚Üíeco_2d.inception_c.inception_3c_double_3x3_reduce_bn.bias\n",
      "module.base_model.inception_3c_double_3x3_reduce_bn.running_mean‚Üíeco_2d.inception_c.inception_3c_double_3x3_reduce_bn.running_mean\n",
      "module.base_model.inception_3c_double_3x3_reduce_bn.running_var‚Üíeco_2d.inception_c.inception_3c_double_3x3_reduce_bn.running_var\n",
      "module.base_model.inception_3c_double_3x3_reduce_bn.num_batches_tracked‚Üíeco_2d.inception_c.inception_3c_double_3x3_reduce_bn.num_batches_tracked\n",
      "module.base_model.inception_3c_double_3x3_1.weight‚Üíeco_2d.inception_c.inception_3c_double_3x3_1.weight\n",
      "module.base_model.inception_3c_double_3x3_1.bias‚Üíeco_2d.inception_c.inception_3c_double_3x3_1.bias\n",
      "module.base_model.inception_3c_double_3x3_1_bn.weight‚Üíeco_2d.inception_c.inception_3c_double_3x3_1_bn.weight\n",
      "module.base_model.inception_3c_double_3x3_1_bn.bias‚Üíeco_2d.inception_c.inception_3c_double_3x3_1_bn.bias\n",
      "module.base_model.inception_3c_double_3x3_1_bn.running_mean‚Üíeco_2d.inception_c.inception_3c_double_3x3_1_bn.running_mean\n",
      "module.base_model.inception_3c_double_3x3_1_bn.running_var‚Üíeco_2d.inception_c.inception_3c_double_3x3_1_bn.running_var\n",
      "module.base_model.inception_3c_double_3x3_1_bn.num_batches_tracked‚Üíeco_2d.inception_c.inception_3c_double_3x3_1_bn.num_batches_tracked\n",
      "module.base_model.res3a_2.weight‚Üíeco_3d.res_3d_3.res3a_2.weight\n",
      "module.base_model.res3a_2.bias‚Üíeco_3d.res_3d_3.res3a_2.bias\n",
      "module.base_model.res3a_bn.weight‚Üíeco_3d.res_3d_3.res3a_bn.weight\n",
      "module.base_model.res3a_bn.bias‚Üíeco_3d.res_3d_3.res3a_bn.bias\n",
      "module.base_model.res3a_bn.running_mean‚Üíeco_3d.res_3d_3.res3a_bn.running_mean\n",
      "module.base_model.res3a_bn.running_var‚Üíeco_3d.res_3d_3.res3a_bn.running_var\n",
      "module.base_model.res3a_bn.num_batches_tracked‚Üíeco_3d.res_3d_3.res3a_bn.num_batches_tracked\n",
      "module.base_model.res3b_1.weight‚Üíeco_3d.res_3d_3.res3b_1.weight\n",
      "module.base_model.res3b_1.bias‚Üíeco_3d.res_3d_3.res3b_1.bias\n",
      "module.base_model.res3b_1_bn.weight‚Üíeco_3d.res_3d_3.res3b_1_bn.weight\n",
      "module.base_model.res3b_1_bn.bias‚Üíeco_3d.res_3d_3.res3b_1_bn.bias\n",
      "module.base_model.res3b_1_bn.running_mean‚Üíeco_3d.res_3d_3.res3b_1_bn.running_mean\n",
      "module.base_model.res3b_1_bn.running_var‚Üíeco_3d.res_3d_3.res3b_1_bn.running_var\n",
      "module.base_model.res3b_1_bn.num_batches_tracked‚Üíeco_3d.res_3d_3.res3b_1_bn.num_batches_tracked\n",
      "module.base_model.res3b_2.weight‚Üíeco_3d.res_3d_3.res3b_2.weight\n",
      "module.base_model.res3b_2.bias‚Üíeco_3d.res_3d_3.res3b_2.bias\n",
      "module.base_model.res3b_bn.weight‚Üíeco_3d.res_3d_3.res3b_bn.weight\n",
      "module.base_model.res3b_bn.bias‚Üíeco_3d.res_3d_3.res3b_bn.bias\n",
      "module.base_model.res3b_bn.running_mean‚Üíeco_3d.res_3d_3.res3b_bn.running_mean\n",
      "module.base_model.res3b_bn.running_var‚Üíeco_3d.res_3d_3.res3b_bn.running_var\n",
      "module.base_model.res3b_bn.num_batches_tracked‚Üíeco_3d.res_3d_3.res3b_bn.num_batches_tracked\n",
      "module.base_model.res4a_1.weight‚Üíeco_3d.res_3d_4.res4a_1.weight\n",
      "module.base_model.res4a_1.bias‚Üíeco_3d.res_3d_4.res4a_1.bias\n",
      "module.base_model.res4a_1_bn.weight‚Üíeco_3d.res_3d_4.res4a_1_bn.weight\n",
      "module.base_model.res4a_1_bn.bias‚Üíeco_3d.res_3d_4.res4a_1_bn.bias\n",
      "module.base_model.res4a_1_bn.running_mean‚Üíeco_3d.res_3d_4.res4a_1_bn.running_mean\n",
      "module.base_model.res4a_1_bn.running_var‚Üíeco_3d.res_3d_4.res4a_1_bn.running_var\n",
      "module.base_model.res4a_1_bn.num_batches_tracked‚Üíeco_3d.res_3d_4.res4a_1_bn.num_batches_tracked\n",
      "module.base_model.res4a_2.weight‚Üíeco_3d.res_3d_4.res4a_2.weight\n",
      "module.base_model.res4a_2.bias‚Üíeco_3d.res_3d_4.res4a_2.bias\n",
      "module.base_model.res4a_down.weight‚Üíeco_3d.res_3d_4.res4a_down.weight\n",
      "module.base_model.res4a_down.bias‚Üíeco_3d.res_3d_4.res4a_down.bias\n",
      "module.base_model.res4a_bn.weight‚Üíeco_3d.res_3d_4.res4a_bn.weight\n",
      "module.base_model.res4a_bn.bias‚Üíeco_3d.res_3d_4.res4a_bn.bias\n",
      "module.base_model.res4a_bn.running_mean‚Üíeco_3d.res_3d_4.res4a_bn.running_mean\n",
      "module.base_model.res4a_bn.running_var‚Üíeco_3d.res_3d_4.res4a_bn.running_var\n",
      "module.base_model.res4a_bn.num_batches_tracked‚Üíeco_3d.res_3d_4.res4a_bn.num_batches_tracked\n",
      "module.base_model.res4b_1.weight‚Üíeco_3d.res_3d_4.res4b_1.weight\n",
      "module.base_model.res4b_1.bias‚Üíeco_3d.res_3d_4.res4b_1.bias\n",
      "module.base_model.res4b_1_bn.weight‚Üíeco_3d.res_3d_4.res4b_1_bn.weight\n",
      "module.base_model.res4b_1_bn.bias‚Üíeco_3d.res_3d_4.res4b_1_bn.bias\n",
      "module.base_model.res4b_1_bn.running_mean‚Üíeco_3d.res_3d_4.res4b_1_bn.running_mean\n",
      "module.base_model.res4b_1_bn.running_var‚Üíeco_3d.res_3d_4.res4b_1_bn.running_var\n",
      "module.base_model.res4b_1_bn.num_batches_tracked‚Üíeco_3d.res_3d_4.res4b_1_bn.num_batches_tracked\n",
      "module.base_model.res4b_2.weight‚Üíeco_3d.res_3d_4.res4b_2.weight\n",
      "module.base_model.res4b_2.bias‚Üíeco_3d.res_3d_4.res4b_2.bias\n",
      "module.base_model.res4b_bn.weight‚Üíeco_3d.res_3d_4.res4b_bn.weight\n",
      "module.base_model.res4b_bn.bias‚Üíeco_3d.res_3d_4.res4b_bn.bias\n",
      "module.base_model.res4b_bn.running_mean‚Üíeco_3d.res_3d_4.res4b_bn.running_mean\n",
      "module.base_model.res4b_bn.running_var‚Üíeco_3d.res_3d_4.res4b_bn.running_var\n",
      "module.base_model.res4b_bn.num_batches_tracked‚Üíeco_3d.res_3d_4.res4b_bn.num_batches_tracked\n",
      "module.base_model.res5a_1.weight‚Üíeco_3d.res_3d_5.res5a_1.weight\n",
      "module.base_model.res5a_1.bias‚Üíeco_3d.res_3d_5.res5a_1.bias\n",
      "module.base_model.res5a_1_bn.weight‚Üíeco_3d.res_3d_5.res5a_1_bn.weight\n",
      "module.base_model.res5a_1_bn.bias‚Üíeco_3d.res_3d_5.res5a_1_bn.bias\n",
      "module.base_model.res5a_1_bn.running_mean‚Üíeco_3d.res_3d_5.res5a_1_bn.running_mean\n",
      "module.base_model.res5a_1_bn.running_var‚Üíeco_3d.res_3d_5.res5a_1_bn.running_var\n",
      "module.base_model.res5a_1_bn.num_batches_tracked‚Üíeco_3d.res_3d_5.res5a_1_bn.num_batches_tracked\n",
      "module.base_model.res5a_2.weight‚Üíeco_3d.res_3d_5.res5a_2.weight\n",
      "module.base_model.res5a_2.bias‚Üíeco_3d.res_3d_5.res5a_2.bias\n",
      "module.base_model.res5a_down.weight‚Üíeco_3d.res_3d_5.res5a_down.weight\n",
      "module.base_model.res5a_down.bias‚Üíeco_3d.res_3d_5.res5a_down.bias\n",
      "module.base_model.res5a_bn.weight‚Üíeco_3d.res_3d_5.res5a_bn.weight\n",
      "module.base_model.res5a_bn.bias‚Üíeco_3d.res_3d_5.res5a_bn.bias\n",
      "module.base_model.res5a_bn.running_mean‚Üíeco_3d.res_3d_5.res5a_bn.running_mean\n",
      "module.base_model.res5a_bn.running_var‚Üíeco_3d.res_3d_5.res5a_bn.running_var\n",
      "module.base_model.res5a_bn.num_batches_tracked‚Üíeco_3d.res_3d_5.res5a_bn.num_batches_tracked\n",
      "module.base_model.res5b_1.weight‚Üíeco_3d.res_3d_5.res5b_1.weight\n",
      "module.base_model.res5b_1.bias‚Üíeco_3d.res_3d_5.res5b_1.bias\n",
      "module.base_model.res5b_1_bn.weight‚Üíeco_3d.res_3d_5.res5b_1_bn.weight\n",
      "module.base_model.res5b_1_bn.bias‚Üíeco_3d.res_3d_5.res5b_1_bn.bias\n",
      "module.base_model.res5b_1_bn.running_mean‚Üíeco_3d.res_3d_5.res5b_1_bn.running_mean\n",
      "module.base_model.res5b_1_bn.running_var‚Üíeco_3d.res_3d_5.res5b_1_bn.running_var\n",
      "module.base_model.res5b_1_bn.num_batches_tracked‚Üíeco_3d.res_3d_5.res5b_1_bn.num_batches_tracked\n",
      "module.base_model.res5b_2.weight‚Üíeco_3d.res_3d_5.res5b_2.weight\n",
      "module.base_model.res5b_2.bias‚Üíeco_3d.res_3d_5.res5b_2.bias\n",
      "module.base_model.res5b_bn.weight‚Üíeco_3d.res_3d_5.res5b_bn.weight\n",
      "module.base_model.res5b_bn.bias‚Üíeco_3d.res_3d_5.res5b_bn.bias\n",
      "module.base_model.res5b_bn.running_mean‚Üíeco_3d.res_3d_5.res5b_bn.running_mean\n",
      "module.base_model.res5b_bn.running_var‚Üíeco_3d.res_3d_5.res5b_bn.running_var\n",
      "module.base_model.res5b_bn.num_batches_tracked‚Üíeco_3d.res_3d_5.res5b_bn.num_batches_tracked\n",
      "module.new_fc.weight‚Üífc_final.weight\n",
      "module.new_fc.bias‚Üífc_final.bias\n"
     ]
    }
   ],
   "source": [
    "net_model_ECO = \"./weights/ECO_Lite_rgb_model_Kinetics.pth.tar\"\n",
    "pretrained_model = torch.load(net_model_ECO, map_location='cpu')\n",
    "pretrained_model_dict = pretrained_model['state_dict']\n",
    "\n",
    "model_dict = net.state_dict()\n",
    "new_state_dict = load_pretrained_ECO(model_dict, pretrained_model_dict)\n",
    "\n",
    "net.eval()  \n",
    "net.load_state_dict(new_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classification of video data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 512, 1, 1, 1])\n",
      "torch.Size([8, 400])\n"
     ]
    }
   ],
   "source": [
    "net.eval()  \n",
    "\n",
    "batch_iterator = iter(val_dataloader)  \n",
    "imgs_transformeds, labels, label_ids, dir_path = next(\n",
    "    batch_iterator)  \n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    outputs = net(imgs_transformeds)  \n",
    "\n",
    "print(outputs.shape)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./data/kinetics_videos/bungee jumping/zkXOcxGnUhs_000025_000035',\n",
       " './data/kinetics_videos/bungee jumping/dAeUFSdYG1I_000010_000020',\n",
       " './data/kinetics_videos/bungee jumping/TUvSX0pYu4o_000002_000012',\n",
       " './data/kinetics_videos/bungee jumping/b6yQZjPE26c_000023_000033',\n",
       " './data/kinetics_videos/arm wrestling/BdMiTo_OtnU_000024_000034',\n",
       " './data/kinetics_videos/arm wrestling/5JzkrOVhPOw_000027_000037',\n",
       " './data/kinetics_videos/arm wrestling/ehLnj7pXnYE_000027_000037',\n",
       " './data/kinetics_videos/arm wrestling/C4lCVBZ3ux0_000028_000038')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_eco_inference_result(dir_path, outputs_input, id_label_dict, idx):\n",
    "    print(\"FileÔºö\", dir_path[idx])  \n",
    "    \n",
    "    outputs = outputs_input.clone()  \n",
    "    \n",
    "    \n",
    "    for i in range(5):\n",
    "      \n",
    "        output = outputs[idx]\n",
    "        \n",
    "        _, pred = torch.max(output, dim=0) \n",
    "        \n",
    "        class_idx = int(pred.numpy())\n",
    "        \n",
    "        print(\"Forcast{}Ôºö{}\".format(i+1, id_label_dict[class_idx]))\n",
    "        outputs[idx][class_idx] = -1000  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('File\\xef\\xbc\\x9a', './data/kinetics_videos/bungee jumping/zkXOcxGnUhs_000025_000035')\n",
      "Forcast1Ôºöbungee jumping\n",
      "Forcast2Ôºöskydiving\n",
      "Forcast3Ôºödiving cliff\n",
      "Forcast4Ôºöcatching fish\n",
      "Forcast5Ôºöfeeding fish\n"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "show_eco_inference_result(dir_path, outputs, id_label_dict, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('File\\xef\\xbc\\x9a', './data/kinetics_videos/arm wrestling/5JzkrOVhPOw_000027_000037')\n",
      "Forcast1Ôºöarm wrestling\n",
      "Forcast2Ôºöstretching leg\n",
      "Forcast3Ôºöheadbutting\n",
      "Forcast4Ôºöshaking hands\n",
      "Forcast5Ôºömassaging feet\n"
     ]
    }
   ],
   "source": [
    "idx = 5\n",
    "show_eco_inference_result(dir_path, outputs, id_label_dict, idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('File\\xef\\xbc\\x9a', './data/kinetics_videos/arm wrestling/C4lCVBZ3ux0_000028_000038')\n",
      "Forcast1Ôºöarm wrestling\n",
      "Forcast2Ôºöheadbutting\n",
      "Forcast3Ôºöshaking hands\n",
      "Forcast4Ôºöstretching leg\n",
      "Forcast5Ôºötai chi\n"
     ]
    }
   ],
   "source": [
    "idx = 7\n",
    "show_eco_inference_result(dir_path, outputs, id_label_dict, idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('File\\xef\\xbc\\x9a', './data/kinetics_videos/bungee jumping/TUvSX0pYu4o_000002_000012')\n",
      "Forcast1Ôºöbungee jumping\n",
      "Forcast2Ôºötrapezing\n",
      "Forcast3Ôºöabseiling\n",
      "Forcast4Ôºöswinging on something\n",
      "Forcast5Ôºöclimbing a rope\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "show_eco_inference_result(dir_path, outputs, id_label_dict, idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_eco_inference_result_10(dir_path, outputs_input, id_label_dict, idx):\n",
    "    print(\"FileÔºö\", dir_path[idx])  \n",
    "    \n",
    "    outputs = outputs_input.clone()  \n",
    "    \n",
    "    \n",
    "    for i in range(10):\n",
    "      \n",
    "        output = outputs[idx]\n",
    "        \n",
    "        _, pred = torch.max(output, dim=0) \n",
    "        \n",
    "        class_idx = int(pred.numpy())\n",
    "        \n",
    "        print(\"Forcast{}Ôºö{}\".format(i+1, id_label_dict[class_idx]))\n",
    "        outputs[idx][class_idx] = -1000  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('File\\xef\\xbc\\x9a', './data/kinetics_videos/bungee jumping/TUvSX0pYu4o_000002_000012')\n",
      "Forcast1Ôºöbungee jumping\n",
      "Forcast2Ôºötrapezing\n",
      "Forcast3Ôºöabseiling\n",
      "Forcast4Ôºöswinging on something\n",
      "Forcast5Ôºöclimbing a rope\n",
      "Forcast6Ôºöparasailing\n",
      "Forcast7Ôºöpole vault\n",
      "Forcast8Ôºösailing\n",
      "Forcast9Ôºöclimbing ladder\n",
      "Forcast10Ôºöcleaning windows\n"
     ]
    }
   ],
   "source": [
    "idx = 2\n",
    "show_eco_inference_result_10(dir_path, outputs, id_label_dict, idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
